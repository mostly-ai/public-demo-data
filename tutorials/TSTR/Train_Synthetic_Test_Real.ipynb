{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUvsR-mWBoNS"
   },
   "source": [
    "# Train-Synthetic-Test-Real\n",
    "\n",
    "In this workbook, we show how to assess synthetic data quality with respect to its utility for a downstream ML task. The demonstrated approach is also known as the Train-Synthetic-Test-Real (TSTR) evaluation. See image below for the setup.\n",
    "\n",
    "<center><img src='./TSTR.png' width=\"600px\"/></center>\n",
    "\n",
    "Thus, we take actual (=real) data, and split it into a holdout and a training dataset. Next, we create a synthetic dataset only based on the training data. Then we train a Machine Learning (ML) model, and do so once using the synthetic data and once using the actual training data. And finally we evaluate the performance of each of those two models on top of the actual holdout data, that was kept aside all along. By comparing the performance of these two models, we can assess how much utility has been retained by the synthesization method with respect to a specific ML task.\n",
    "\n",
    "Note, that one needs to use a true holdout for the evaluation to properly measure out-of-sample performance, which is relevant for real-world use cases. If one uses the same training data that has been used for the synthesis, one would \"leak\" information from training into evaluation. This becomes particularly an issue for synthesizers that are prone to overfitting, and simply memorize the samples it has been exposed to. If one, on the other hand, would use synthetic data for the evaluation, one would not get meaningful results either, if the synthetic data itself is not representative of real data. E.g., consider the case of a synthesizer that only generates the same record over and over again. Then any model trained on that data, would yield perfect results when evaluated on it again, whereas it will be of no use when applied to real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZ7ERZK__8TB"
   },
   "source": [
    "## Fetch Actual Training Data and Synthesize it via MOSTLY AI\n",
    "\n",
    "1. Download `census-training.csv` from [here](https://github.com/mostly-ai/public-demo-data/raw/dev/census/census-training.csv). This is a 80% random sample of the Adult Income dataset. The corresponding remaining 20% records can, will be fetched directly further below.\n",
    "2. Synthesize `census-training.csv` via [MOSTLY AI](https://mostly.ai/) - you can leave all default settings as-is.\n",
    "3. Upload the generated synthetic data to this Notebook via executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "uTR_dshPG4vZ",
    "outputId": "4aab330a-29e2-48a0-8831-517d0bb7a55a"
   },
   "outputs": [],
   "source": [
    "# upload synthetic dataset\n",
    "import pandas as pd\n",
    "try:\n",
    "    # check whether we are in Google colab\n",
    "    from google.colab import files\n",
    "    import io\n",
    "    uploaded = files.upload()\n",
    "    syn = pd.read_csv(io.BytesIO(list(uploaded.values())[0]))\n",
    "    print(f\"uploaded synthetic data with {syn.shape[0]:,} records and {syn.shape[1]:,} attributes\")\n",
    "except:\n",
    "    syn = pd.read_csv('census-synthetic.csv')\n",
    "    print(f\"use previously synthesized dataset with {syn.shape[0]:,} records and {syn.shape[1]:,} attributes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjXi6p1j-vZK",
    "outputId": "838dd765-9d17-4940-fc82-18819cdb0206"
   },
   "outputs": [],
   "source": [
    "# fetch training and holdout data directly from S3 bucket\n",
    "import pandas as pd\n",
    "train = pd.read_csv('census-training.csv')\n",
    "print(f'fetched training data with {train.shape[0]:,} records and {train.shape[1]} attributes')\n",
    "holdout = pd.read_csv('census-holdout.csv')\n",
    "print(f'fetched holdout data with {holdout.shape[0]:,} records and {holdout.shape[1]} attributes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgvJ0XoWTHoX"
   },
   "source": [
    "## Compare ML Performance\n",
    "\n",
    "We use a state-of-the-art LightGBM classifier as our downstream ML model, and train it for the task of predicting the `income` column, based on all other 14 features. Thus, given the `age`, `education`, `marital-status`, etc. information on a subject, we intend to predict whether that person reported an annual income of more than $50K or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rl6-YXB_e0Ac"
   },
   "outputs": [],
   "source": [
    "# define ML model training pipeline, including data preparation, model training, and model evaluation\n",
    "\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# prepare data, and split into features `X` and target `y`\n",
    "def prepare_xy(df: pd.DataFrame):\n",
    "    tgt_col = 'income'\n",
    "    y = (df[tgt_col]=='>50K').astype(int)\n",
    "    str_cols = [col for col in df.select_dtypes(['object', 'string']).columns if col != tgt_col]\n",
    "    for col in str_cols:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "    cat_cols = [col for col in df.select_dtypes('category').columns if col != tgt_col]\n",
    "    num_cols = [col for col in df.select_dtypes('number').columns if col != tgt_col]\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].astype('float')\n",
    "    X = df[cat_cols + num_cols]\n",
    "    return X, y\n",
    "\n",
    "# train ML model with early stopping\n",
    "def train_model(X, y):\n",
    "    cat_cols = list(X.select_dtypes('category').columns)\n",
    "    X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    ds_trn = lgb.Dataset(X_trn, label=y_trn, categorical_feature=cat_cols, free_raw_data=False)\n",
    "    ds_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_cols, free_raw_data=False)\n",
    "    print(f\"X_trn: {X_trn.shape[0]:,} rows, {X_trn.shape[1]:,} columns, target: {y_trn.mean():.2%}\")\n",
    "    print(f\"X_val: {X_val.shape[0]:,} rows, {X_val.shape[1]:,} columns, target: {y_val.mean():.2%}\")\n",
    "    model = lgb.train(\n",
    "        num_boost_round=200, \n",
    "        params={\n",
    "            'verbose': -1,\n",
    "            'metric': 'auc',  \n",
    "            'objective': 'binary'\n",
    "        }, \n",
    "        train_set=ds_trn,\n",
    "        valid_sets=[ds_val],\n",
    "        callbacks=[early_stopping(5)],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# apply ML Model to some holdout data, report key metrics, and visualize scores\n",
    "def evaluate_model(model, hol):\n",
    "    X_hol, y_hol = prepare_xy(hol)\n",
    "    probs = model.predict(X_hol)\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_hol, probs)\n",
    "    acc = accuracy_score(y_hol, preds)\n",
    "    print(\"\")\n",
    "    print(f\"Holdout Accuracy {acc:.1%}\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(pd.crosstab(pd.Series(preds, name='predicted'), y_hol))\n",
    "    print(\"\")\n",
    "    probs_df = pd.concat([\n",
    "        pd.Series(probs, name='probability').reset_index(drop=True),\n",
    "        pd.Series(y_hol, name='target').reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    fig = sns.displot(data=probs_df, x='probability', hue='target', bins=20, palette=['#008CFB', '#FF004F'])\n",
    "    fig = plt.title(f\"Holdout AUC: {auc:.3f}\", fontsize = 20)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TlKk4PLmB-0b"
   },
   "source": [
    "### Train ML Model on Real Data: `model_trn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtQiGZdyCB72",
    "outputId": "fb0fa7ad-c3f3-4d8a-d907-a7248e770e6d"
   },
   "outputs": [],
   "source": [
    "X_trn, y_trn = prepare_xy(train)\n",
    "model_trn = train_model(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDK1Jr_xhBnl"
   },
   "source": [
    "### Train ML Model on Synthetic Data: `model_syn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14CMIhcvgQ77",
    "outputId": "f8f46533-b092-4ec7-8ecd-c2f5c51961ec"
   },
   "outputs": [],
   "source": [
    "X_syn, y_syn = prepare_xy(syn)\n",
    "model_syn = train_model(X_syn, y_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bwKgsJ3EmJB"
   },
   "source": [
    "### Evaluate `model_trn` on actual holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "tneTdK4NEnz7",
    "outputId": "d3730edb-0aac-48f8-a1c9-46bc1c0f2f6a"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model_trn, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fipgm179hYuS"
   },
   "source": [
    "### Evaluate `model_syn` on actual holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "g5VaT4w-hMZ5",
    "outputId": "fd4a6cbb-8044-407d-c5e9-4a077ed16011"
   },
   "outputs": [],
   "source": [
    "evaluate_model(model_syn, holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMGNussThvys"
   },
   "source": [
    "## Wrap-Up\n",
    "\n",
    "**Summary**: For the provided dataset, you see a near on-par performance with respect to the downstream ML task. \n",
    "\n",
    "TODO: spell out implications\n",
    "\n",
    "**Further exercise**: \n",
    "* You can now try to run Train-Synthetic-Test-Real on a different dataset, using the same or a different downstream ML model class. For that you will need to do the splitting of the actual data into `train` and `holdout` yourself, e.g. via the previously used [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method. \n",
    "* You can also try to see whether you can improve the accuracy of the downstream model by synthetic upsampling, i.e. by generating and then using significantly more synthetic samples than were contained in the actual training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsQ823qxih-M"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
